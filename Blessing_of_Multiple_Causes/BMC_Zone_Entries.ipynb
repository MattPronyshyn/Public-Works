{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "import scipy.stats as stats\n",
    "import pymc as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import helper_functions as hf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantitavely Assessing The Impact of Invididual Players in Hockey Offensive Zone Entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "Making two datasets, one for only the offensive team's players and one for the defendings team's players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/zone_entries_with_players.csv')\n",
    "zone_entries_df = data.iloc[:, [9] + list(range(31, 82))]\n",
    "shifts_df = pd.read_csv('Data/BDC_2024_Womens_Shifts.csv')\n",
    "\n",
    "# Remove the goalies from the shifts data\n",
    "players_to_remove = ['Aerin Frankel', 'Emerance Maschmeyer', 'Kristen Campbell', 'Nicole Hensley', 'Ann-Renee Desbiens']\n",
    "shifts_df = shifts_df[~shifts_df['player_name'].isin(players_to_remove)]\n",
    "\n",
    "# Get the player names and team names\n",
    "player_teams_df = shifts_df[['team_name', 'player_name']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This splits game entry data into two datasets by filtering each player's contributions: one dataset retains data when the player’s team matches the entry’s team (offensive), and the other retains data when it does not (defensive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "offensive_dataset, defensive_dataset = hf.create_offensive_defensive_datasets(zone_entries_df, player_teams_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model implements a latent factor decomposition using a Poisson likelihood. For an observed $Y_{ij}$ corresponding to zone entry $i$ and player $j$, we assume\n",
    "\n",
    "$$\n",
    "Y_{ij} \\sim \\text{Poisson}(\\lambda_{ij}),\n",
    "$$\n",
    "\n",
    "with the Poisson rate parameter defined as the dot product of two latent factors:\n",
    "\n",
    "$$\n",
    "\\lambda_{ij} = \\mathbf{z}_i \\cdot \\mathbf{w}_j^T.\n",
    "$$\n",
    "\n",
    "The latent factors are given Gamma priors:\n",
    "\n",
    "$$\n",
    "\\mathbf{z}_i \\sim \\text{Gamma}(\\alpha=1, \\beta=1) \\quad \\text{for } i=1,\\dots,N,\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{w}_j \\sim \\text{Gamma}(\\alpha=1, \\beta=1) \\quad \\text{for } j=1,\\dots,M.\n",
    "$$\n",
    "\n",
    "Here, $\\mathbf{z}_i$ represents the latent factors for the zone entries and $\\mathbf{w}_j$ represents the latent factors for the players. In this implementation, we use a latent space of dimension 2. We choose a two-dimensional model because the dataset is very small and increasing the dimensionality does not significantly improve performance; the goal here is merely to demonstrate feasibility. \n",
    "\n",
    "Separate models are defined for the offensive and defensive datasets, allowing for context-specific latent representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [zone_entry_factors, player_factors]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 02:22&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 156 seconds.\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [zone_entry_factors, player_factors]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 02:26&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 159 seconds.\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as poisson_factorization_offensive:\n",
    "\n",
    "    # Priors for the factors\n",
    "    zone_entry_factors = pm.Gamma('zone_entry_factors', alpha=1, beta=1, shape=(offensive_dataset.shape[0], 2))\n",
    "    player_factors = pm.Gamma('player_factors', alpha=1, beta=1, shape=(offensive_dataset.shape[1], 2))\n",
    "\n",
    "    # Expected value parameter for the Poisson likelihood\n",
    "    rate = pm.math.dot(zone_entry_factors, player_factors.T)\n",
    "\n",
    "    # Poisson likelihood for the observed data\n",
    "    observed_counts = pm.Poisson('observed_counts', mu=rate, observed=offensive_dataset)\n",
    "\n",
    "    # Sampling\n",
    "    trace_offensive = pm.sample(return_inferencedata=True)\n",
    "    \n",
    "with pm.Model() as poisson_factorization_defensive:\n",
    "\n",
    "    # Priors for the factors\n",
    "    zone_entry_factors = pm.Gamma('zone_entry_factors', alpha=1, beta=1, shape=(defensive_dataset.shape[0], 2))\n",
    "    player_factors = pm.Gamma('player_factors', alpha=1, beta=1, shape=(defensive_dataset.shape[1], 2))\n",
    "\n",
    "    # Expected value parameter for the Poisson likelihood\n",
    "    rate = pm.math.dot(zone_entry_factors, player_factors.T)\n",
    "\n",
    "    # Poisson likelihood for the observed data\n",
    "    observed_counts = pm.Poisson('observed_counts', mu=rate, observed=defensive_dataset)\n",
    "\n",
    "    # Sampling\n",
    "    trace_defensive = pm.sample(return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"366pt\" height=\"260pt\"\n",
       " viewBox=\"0.00 0.00 366.00 259.91\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 255.91)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-255.91 362,-255.91 362,4 -4,4\"/>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster51 x 2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M214,-129.95C214,-129.95 338,-129.95 338,-129.95 344,-129.95 350,-135.95 350,-141.95 350,-141.95 350,-231.91 350,-231.91 350,-237.91 344,-243.91 338,-243.91 338,-243.91 214,-243.91 214,-243.91 208,-243.91 202,-237.91 202,-231.91 202,-231.91 202,-141.95 202,-141.95 202,-135.95 208,-129.95 214,-129.95\"/>\n",
       "<text text-anchor=\"middle\" x=\"324.5\" y=\"-137.75\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">51 x 2</text>\n",
       "</g>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster527 x 2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M20,-129.95C20,-129.95 182,-129.95 182,-129.95 188,-129.95 194,-135.95 194,-141.95 194,-141.95 194,-231.91 194,-231.91 194,-237.91 188,-243.91 182,-243.91 182,-243.91 20,-243.91 20,-243.91 14,-243.91 8,-237.91 8,-231.91 8,-231.91 8,-141.95 8,-141.95 8,-135.95 14,-129.95 20,-129.95\"/>\n",
       "<text text-anchor=\"middle\" x=\"165\" y=\"-137.75\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">527 x 2</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster527 x 51</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M111,-8C111,-8 255,-8 255,-8 261,-8 267,-14 267,-20 267,-20 267,-109.95 267,-109.95 267,-115.95 261,-121.95 255,-121.95 255,-121.95 111,-121.95 111,-121.95 105,-121.95 99,-115.95 99,-109.95 99,-109.95 99,-20 99,-20 99,-14 105,-8 111,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"234.5\" y=\"-15.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">527 x 51</text>\n",
       "</g>\n",
       "<!-- zone_entry_factors -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>zone_entry_factors</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"101\" cy=\"-198.43\" rx=\"84.71\" ry=\"37.45\"/>\n",
       "<text text-anchor=\"middle\" x=\"101\" y=\"-209.73\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">zone_entry_factors</text>\n",
       "<text text-anchor=\"middle\" x=\"101\" y=\"-194.73\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"101\" y=\"-179.73\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Gamma</text>\n",
       "</g>\n",
       "<!-- observed_counts -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>observed_counts</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"183\" cy=\"-76.48\" rx=\"75.82\" ry=\"37.45\"/>\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-87.78\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">observed_counts</text>\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-72.78\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"183\" y=\"-57.78\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Poisson</text>\n",
       "</g>\n",
       "<!-- zone_entry_factors&#45;&gt;observed_counts -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>zone_entry_factors&#45;&gt;observed_counts</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M124.94,-162.41C133.86,-149.36 144.1,-134.38 153.47,-120.67\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.42,-122.56 159.17,-112.33 150.64,-118.61 156.42,-122.56\"/>\n",
       "</g>\n",
       "<!-- player_factors -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>player_factors</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"276\" cy=\"-198.43\" rx=\"66.44\" ry=\"37.45\"/>\n",
       "<text text-anchor=\"middle\" x=\"276\" y=\"-209.73\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">player_factors</text>\n",
       "<text text-anchor=\"middle\" x=\"276\" y=\"-194.73\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"276\" y=\"-179.73\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Gamma</text>\n",
       "</g>\n",
       "<!-- player_factors&#45;&gt;observed_counts -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>player_factors&#45;&gt;observed_counts</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M249.85,-163.7C239.34,-150.14 227.1,-134.36 215.99,-120.03\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"218.5,-117.55 209.6,-111.79 212.96,-121.84 218.5,-117.55\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x2466f877160>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.model_to_graphviz(poisson_factorization_offensive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Check\n",
    "\n",
    "This section performs predictive checks to evaluate whether the latent factor model adequately captures the structure in the data. By comparing simulated data from the model with the observed zone entry successes, we assess model fit and identify any potential mis-specifications. This process helps ensure that our inferred latent representations are reliable for subsequent analyses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block randomly withholds a small subset of observed counts from the offensive dataset, three player‑zone entries per row, to serve as held‑out data for predictive checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "np.random.seed(2)\n",
    "num_mask = 3\n",
    "# Mask creation \n",
    "mask = np.ones_like(offensive_dataset, dtype=bool)\n",
    "for i in range(offensive_dataset.shape[0]):\n",
    "    mask_indices = np.random.choice(offensive_dataset.shape[1], num_mask, replace=False)\n",
    "    mask[i, mask_indices] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'helper_functions' has no attribute 'predictive_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Compute predictive scores\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m offensive_score \u001b[38;5;241m=\u001b[39m \u001b[43mhf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictive_score\u001b[49m(offensive_dataset, mask, num_mask)\n\u001b[0;32m      3\u001b[0m defensive_score \u001b[38;5;241m=\u001b[39m hf\u001b[38;5;241m.\u001b[39mpredictive_score(defensive_dataset, mask, num_mask)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOffensive held‑out predictive score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moffensive_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'helper_functions' has no attribute 'predictive_score'"
     ]
    }
   ],
   "source": [
    "# Compute predictive scores\n",
    "offensive_score = hf.predictive_score(offensive_dataset, mask, num_mask)\n",
    "defensive_score = hf.predictive_score(defensive_dataset, mask, num_mask)\n",
    "\n",
    "print(f\"Offensive held‑out predictive score: {offensive_score:.3f}\")\n",
    "print(f\"Defensive held‑out predictive score: {defensive_score:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
